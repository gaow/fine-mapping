{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Summary statistics data mungling in preparation for fine-mapping pipelines\n",
    "\n",
    "This pipeline extracts loci of interest from association analysis summary statistics data, intersecting it with genotype data to compute correlation matrix, and output the data-set per loci with summary statistics and genotype correlations matched. Additionally it extracts prior inclusion probability (annotation scores) for each variant in the data-set, if the information is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This pipeline was devised by Gao Wang and implemented by Min Qiao at The University of Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- Summary statistics file, `gzip` compressed, including 7 columns\n",
    "    - chromsome\n",
    "    - position\n",
    "    - reference allele\n",
    "    - alternative allele\n",
    "    - z-score\n",
    "    - ${\\beta}$ (effect size)\n",
    "    - standard error (se)\n",
    "\n",
    "  **Input have to be sorted by chromosome and position!**\n",
    "\n",
    "\n",
    "- Loci file, similar in flavor to `bed` files.\n",
    "\n",
    "      1st column is chr; 2nd is chunk start position; 3rd is chunk end position; 4th is loci identifier.\n",
    "\n",
    "        chr22\t44995308\t46470495\t1699\n",
    "        chr22\t46470495\t47596318\t1700\n",
    "        chr22\t47596318\t48903703\t1701\n",
    "        chr22\t48903703\t49824534\t1702\n",
    "        chr22\t49824534\t51243298\t1703\n",
    "        \n",
    "  If the last column is not available the first 3 columns will be concatenated to become the loci identifier. \n",
    "\n",
    "  Note that default data-base for loci can be, naturally, LD blocks. For example European genomes are typically divided into 1703 LD chunks (exclude X chromosome).\n",
    "\n",
    "\n",
    "- Prior inclusion probability, for example:\n",
    "\n",
    "      1st columns format “chr:bp:ref:alt”，2nd is prior\n",
    "\n",
    "        1:1847856:T:G  1.4413e-04\n",
    "        1:1847979:T:C  7.3716e-05\n",
    "        1:1848109:C:G  1.4413e-04\n",
    "        1:1848160:A:G  1.4413e-04\n",
    "        1:1848734:A:G  7.3716e-05\n",
    "        \n",
    "  This is the default format from the enrichment analysis tool called `torus`.\n",
    "  \n",
    "- Genotype data reference panel (or panels if by chromosome), in VCF format. Ideally this is the genotype data used to generate the summary statistics; but external reference panel can also be used. \n",
    "A popular choice is [1000 Genomes (data download)](http://hgdownload.cse.ucsc.edu/gbdb/hg19/1000Genomes/phase3) for genotypes of \n",
    "[different population (data download)](ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel).\n",
    "    - There are 503 Europeans (`EUR`) in 1000 Genomes data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pitfalls in data mungling with external reference panel\n",
    "\n",
    "1. Genomic coordinate can be zero- or one-based. That means SNP positions can start from **start from 0**, instead of 1. This is indeed the case for 1000 Genomes data. In order to be consistent with one-based summary statistics, we need to **add 1** to all 1000 genome SNPs position.\n",
    "2. Reference and alternative alleles may mismatch between summary statistics and the reference panel. If it is a simple ref / alt flip we need to also flip the coding of genotypes or sign of summary statistics to adjust for the effect size direction. If it is strand flip we need to convert summary statistics and genotype data to use the same strand first and take from there. \n",
    "3. When strand flip is involved, cases such as A/T and C/G are no longer identifiable -- whether it be strand flip or ref / alt flip. We will have to remove these locus (having A/T or C/G genotypes) from analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis steps\n",
    "\n",
    "1. Denote summary statistics matrix in the specific loci as $S_1$, and annotation (prior) matrix as $A_1$. The number of row in these two matrices is the number of SNPs in summary statistics of the study of interest.\n",
    "2. Extract corresponding genotype from reference panel in VCF format for this loci. Denote this genotype matrix as $G_1$. Rows are SNPs, columns are population genotypes. \n",
    "    - Genotype coding: we use numeric coding 0, 1 and 2 indicating the number of \"non-reference allele\". In other words we have the following \"mapping rule\":\n",
    "        ```\n",
    "        0|0  ->  0\n",
    "        1|0  ->  1\n",
    "        1|1  ->  2\n",
    "        2|0  ->  1\n",
    "        2|1  ->  2\n",
    "        2|2  ->  2\n",
    "        ```\n",
    "    - Non-variant sites (lines having identical genotypes for everybody) will be removed.\n",
    "    \n",
    "3. Find overlapped SNPs of $S_1$ and $G_1$, then extract new genotype matrix from $G_1$ excluding non-overlaps, denote as $G_2$, and new summary statistics matrix from $S_1$ excluding non-overlaps, denote as $S_2$.\n",
    "4. Compare $G_2$ and $S_2$'s reference and alternative allele, flip coding as necessary, generating new summay statistic matrix $S_3$ and new genotype matrix $G_3$. There could be several situations as follows:\n",
    "\n",
    "    - completely identical;\n",
    "    - Not identical, but identical after switching ref and alt in $S_2$: add opposite sign for z score and beta; does not apply to `A/T`, `T/A`, `G/C` or `C/G` for `ref/alt`;\n",
    "    - Not identical, but identical after strand flip ref and alt in $S_2$: keep the sign of z score and beta; does not apply to `A/T`, `T/A`, `G/C` or `C/G` for `ref/alt`;\n",
    "    - Not identical, but identical after strand flip ref and alt then swith their positions: add opposite sign for z score and beta; only apply to `A/G`, `G/A`, `A/C`, `C/A`, `T/C`, `C/T`, `T/G` and `G/T`.\n",
    "    - Not identical, `A/T`, `T/A`, `G/C` or `C/G` for `ref/alt`: consider this situation at last; if flip strand has applied in this LD block, then flip strand and keep the sign of z score and beta; if not, switch ref and alt of $S_2$, add opposite sign for z score and beta.\n",
    "    - Not identical after previous 5 substeps: drop.\n",
    "5. Calculate row correlation matrix of $G_3$, denote as $R$. The number of rows and columns of $R$ is the number of SNPs in $G_3$.\n",
    "6. Obtain overlapped SNPs for $S_3$ and $A_1$ and use overlapped SNPs to generate new annotation/prior $A_2$.\n",
    "\n",
    "Notice that if genotype data used to generate the summary statistics is available as reference panel, there should not be a need for 4. But it is a good double-check anyways to do 4 -- we therefore provide an option to specify whether or not we expect step 4 is unnecessary; and if so, throw an error when we found discrepency in 4, instead of trying to fix those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Outputs\n",
    "- $S_3$: the number of rows of $S_3$ is the same with $A_2$. It can be 4 columns, `chr:pos  beta  se  ID`, or 3 columns, `chr:pos z ID`.\n",
    "- $R$: correlation matrix, #SNPs $\\times$ #SNPs of $G_3$.\n",
    "- $A_2$: adjusted annotation/prior information, the number of rows is the same with $S_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/fine_mapping_data"
     ]
    }
   ],
   "source": [
    "%cd /data/fine_mapping_data/\n",
    "this_nb = 'summary_statistics_wrangler.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Current work directory, where output will be written to\n",
    "parameter: cwd = path(\".\")\n",
    "# Reference panel, either VCF file or a manifest file each line is \"chrom number <white space> VCF file name\"\n",
    "# the manifest file have to be in the same folder as the VCF files it refers to.\n",
    "parameter: reference = path()\n",
    "# Loci file\n",
    "parameter: loci = path()\n",
    "# summary statistics\n",
    "parameter: ss_data = path()\n",
    "# Use --no-strand-flip to set it to false\n",
    "# if you are sure there is no strand_flip involved\n",
    "parameter: strand_flip = True\n",
    "# Use --no-ref-flip to set it to false\n",
    "# if you are sure there is no reference / alternative mismatch involved\n",
    "parameter: ref_flip = True\n",
    "\n",
    "# Decide whether or not reference panel matches summary statistics\n",
    "if not ref_flip and not strand_flip:\n",
    "    strictly_match = True\n",
    "else:\n",
    "    strictly_match = False\n",
    "\n",
    "# Check if files exist\n",
    "fail_if(not reference.is_file(), msg = 'Please specify valid path for --reference')\n",
    "fail_if(not loci.is_file(), msg = 'Please specify valid path for --loci')\n",
    "fail_if(not ss_data.is_file(), msg = 'Please specify valid path for --ss-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Preparing external reference genotypes\n",
    "\n",
    "For 1000 genomes data, using `integrated_call_samples_v3.20130502.ALL.panel.txt` file to extract sample ID for given population (eg `EUR`) and subset the data. We only need to run it once.\n",
    "\n",
    "If loci manifest is provided it generate both a new loci manifest file and the files it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Get information about a specified race\n",
    "[prepare_1KG_reference]\n",
    "depends: executable(\"bcftools\"), executable(\"tabix\")\n",
    "# Race identifier in 1000 genomes\n",
    "parameter: race = \"EUR\"\n",
    "# Path to `integrated_call_samples_v3.20130502.ALL.panel.txt`\n",
    "parameter: panel_meta = path()\n",
    "stop_if(not panel_meta.is_file(), msg = 'Please specify valid path for --panel-meta')\n",
    "\n",
    "if str(reference).endswith('vcf.gz'):\n",
    "    chroms = ['0']\n",
    "    genotypes = [reference]\n",
    "else:\n",
    "    manifest = [x.strip().split() for x in open(f'{reference:a}').readlines()]\n",
    "    meta = [x[0] for x in manifest]\n",
    "    genotypes = [x[1] for x in manifest]\n",
    "\n",
    "input: sos_groups(genotypes, by = 1).set_each(\"chrom\", chroms), concurrent = True\n",
    "output: f\"{_input:nn}.{race}.vcf.gz\"\n",
    "bash: expand = True, workdir = cwd\n",
    "    grep -w \"{race}\" {panel_meta} | cut -f 1 > {_output:nn}_extracted.txt\n",
    "    bcftools view -S {_output:nn}_extracted.txt {_input} -Oz > {_output}\n",
    "    tabix -p vcf {_output}\n",
    "    rm {_output:nn}_extracted.txt\n",
    "\n",
    "if not str(reference).endswith('vcf.gz'):\n",
    "    with open(f\"{reference:n}.{race}.{reference:x}\", 'w') as f:\n",
    "        for item in _output:\n",
    "            f.write(f'{item.get(\"chrom\")} {item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run {this_nb} prepare_1KG_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Obtain reference genotypes for given loci: matrix `𝐺1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Get genotype matrix\n",
    "[default_1 (get genotype)]\n",
    "# when set to N (typically 0, 1 or -1) the genomic position\n",
    "# in the panel will be adjusted by N, ie. position = position + N\n",
    "# This is useful when summary stats and reference panel have different coordinates (off by 1 position)\n",
    "parameter: adjust_panel_position = 0\n",
    "depends: Py_Module('cyvcf2')\n",
    "\n",
    "import pandas as pd\n",
    "chunks = [x.tolist() for idx, x in pd.read_table(f'{loci:a}', header = None, sep = '\\s+').iterrows() if not x[0].startswith('#')]\n",
    "if str(reference).endswith('vcf.gz'):\n",
    "    genotype = reference\n",
    "else:\n",
    "    genotype = dict([tuple(x.strip().split()) for x in open(f'{reference:a}').readlines()])\n",
    "    for k in genotype:\n",
    "        genotype[k] = os.path.join(f'{reference:ad}', genotype[k])\n",
    "\n",
    "input: group_by = 1, for_each = 'chunks', concurrent = True\n",
    "output: sos_targets(f\"{ss_data:n}.{_chunks[-1] if len(_chunks) > 3 else '%s_%s_%s' % (_chunks[0], _chunks[1], _chunks[2])}.pkl\").set(\"chunks\", chunks)\n",
    "python3: expand = \"${ }\", workdir = cwd\n",
    "    from cyvcf2 import VCF\n",
    "    import pandas as pd\n",
    "    chromosome = '${_chunks[0].replace(\"chr\",\"\")}'\n",
    "    panel = ${path(genotype[_chunks[0].replace(\"chr\",\"\")] if isinstance(genotype, dict) else genotype):ar}\n",
    "    # loci region\n",
    "    queryid =  chromosome + \":\" + \"${_chunks[1]}\" + \"-\" + \"${_chunks[2]}\"\n",
    "    off_set = ${adjust_panel_position}\n",
    "    # scan VCF chunk\n",
    "    vcf = VCF(panel, gts012=False)\n",
    "    res = []\n",
    "    ## Attention: 1000 Genome position start from 0, not 1! So need to +1 for variant.start\n",
    "    for variant in vcf(queryid):\n",
    "        for i in range(len(variant.ALT)):\n",
    "            line = [f'{variant.CHROM}:{variant.start+off_set}', \n",
    "                    variant.REF, variant.ALT[i]] + \\\n",
    "                    [x[:-1].count(i+1) for x in variant.genotypes]\n",
    "            if len(set(line[3:])) == 1:\n",
    "                # remove non-variant site in reference panel\n",
    "                continue\n",
    "            res.append(line)\n",
    "    gt = pd.DataFrame(res, columns = ['ID', 'ref', 'alt'] + vcf.samples)\n",
    "    gt.to_pickle(${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Obtain summary statistics and the matching genotype correlation for given loci\n",
    "\n",
    "Obtain genotype matrix 𝐺2, summary statistics 𝑆2, compare ref/alt in 𝑆2 and 𝐺2 => 𝑆3 and 𝐺3, calculate 𝑅=row_corr(𝐺3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_2 (get summary stats)]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: summary_stats = f\"{_input:n}.summary_stats.txt\", ld_matrix = f\"{_input:n}.LD.txt\"\n",
    "python3: expand=\"${ }\", stdout = f'{_input:n}.allele_flip.log', workdir = cwd\n",
    "    import pandas as pd, numpy as np\n",
    "    import datetime, sys\n",
    "\n",
    "    def exit_if_empty(x):\n",
    "        if x.empty:\n",
    "            open(\"${_output['summary_stats']}\", 'w').close()\n",
    "            open(\"${_output['ld_matrix']}\", 'w').close()\n",
    "            sys.exit(0)\n",
    "\n",
    "    print(datetime.datetime.now(),\"\\n\")\n",
    "    locus = ${step_input.get(\"chunks\")[_index]}\n",
    "    S1 = pd.read_table(${ss_data:ar}, compression='gzip', header = 0)\n",
    "    S1 = S1[(S1[\"chr\"] == locus[0]) & (S1[\"bp\"] >= int(locus[1])) & (S1[\"bp\"] < int(locus[2]))]\n",
    "    exit_if_empty(S1)\n",
    "    print(\"SAMPLE: %s\\tLENGTH:%d\\n\" % (\"S1\",len(S1)))\n",
    "    S1[\"chr\"] = S1[\"chr\"].str.replace(\"chr\", \"\")\n",
    "    S1[\"ID\"] = S1[\"chr\"] + \":\" + S1[\"bp\"].map(str)\n",
    "    G1 = pd.read_pickle(\"${_input}\")\n",
    "    print(\"SAMPLE: %s\\tLENGTH:%d\\n\" % (\"G1\",len(G1)))\n",
    "    # S2\n",
    "    S2 = S1[S1[\"ID\"].isin(G1[\"ID\"])]\n",
    "    exit_if_empty(S2)\n",
    "    #S2[\"ID\"] = S2[\"ID\"].fillna\n",
    "    print(\"SAMPLE: %s\\tLENGTH:%d\\n\" % (\"S2\",len(S2)))\n",
    "    # 𝐺2\n",
    "    G2 = G1[G1[\"ID\"].isin(S1[\"ID\"])].copy()\n",
    "    exit_if_empty(G2)\n",
    "    print(\"SAMPLE: %s\\tLENGTH:%d\\n\" % (\"G2\",len(G2)))\n",
    "    # 𝑆2 and 𝐺2 : reference and alternative\n",
    "    # at ta cg gc\n",
    "    def gt(s1,s2,s3,s4):\n",
    "        if (s1+s2 == \"AT\" and s3+s4 == \"TA\") or (s1+s2 == \"GC\" and s3+s4 == \"CG\" ) or (s1+s2 == \"TA\" and s3+s4 == \"AT\") or (s1+s2 == \"CG\" and s3+s4 == \"GC\"):\n",
    "            return ${0 if strand_flip else 1}\n",
    "        else:\n",
    "            return 1\n",
    "    # flip\n",
    "    def atcg(inp):\n",
    "        if inp == \"A\":\n",
    "            return \"T\"\n",
    "        elif inp == \"T\":\n",
    "            return \"A\"\n",
    "        elif inp == \"G\":\n",
    "            return \"C\"\n",
    "        elif inp == \"C\":\n",
    "            return \"G\"\n",
    "    # S3 \n",
    "    FLIPD = []\n",
    "    # equal\n",
    "    EQUAL = 0\n",
    "    # flipped by strand \n",
    "    FLIPNUM = 0\n",
    "    # flipped by reference and alternative\n",
    "    REFALTNUM = 0 \n",
    "    \n",
    "    # keep at/ta/cg/gc line numbers\n",
    "    at_cg_id = []\n",
    "\n",
    "\n",
    "    for i in range(len(S2)):\n",
    "        line = list(S2.iloc[i,:2])\n",
    "        old_id = S2.iloc[i,0] + \":\" + str(S2.iloc[i,1]) + \":\" + S2.iloc[i,2] + \":\" + S2.iloc[i,3]\n",
    "        if set([S2.iloc[i,2],S2.iloc[i,3]]) != set([G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0]]):\n",
    "            print (S2.iloc[i,1],S2.iloc[i,2],S2.iloc[i,3],S2.iloc[i,-1], G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0])\n",
    "        # not at/ta/gc/cg\n",
    "        if gt(S2.iloc[i,2],S2.iloc[i,3],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0])==1:\n",
    "            if G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0] == S2.iloc[i,2] and G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0] == S2.iloc[i,3]:\n",
    "                EQUAL+=1\n",
    "                line=S2.iloc[i,:-1].tolist() + [old_id]\n",
    "                FLIPD.append(line)\n",
    "            elif G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0] == S2.iloc[i,2] and G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0] == S2.iloc[i,3]:\n",
    "                REFALTNUM+=1\n",
    "                line.extend([S2.iloc[i,3],S2.iloc[i,2],0-S2.iloc[i,4],0-S2.iloc[i,5],S2.iloc[i,6], old_id])\n",
    "                FLIPD.append(line)\n",
    "            elif atcg(S2.iloc[i,2]) == G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0] and atcg(S2.iloc[i,3]) == G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0]:\n",
    "                FLIPNUM+=1\n",
    "                line.extend([atcg(S2.iloc[i,2]),atcg(S2.iloc[i,3]),S2.iloc[i,4],S2.iloc[i,5],S2.iloc[i,6], old_id])\n",
    "                FLIPD.append(line)\n",
    "            elif atcg(S2.iloc[i,2]) == G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0] and atcg(S2.iloc[i,3]) == G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0]:\n",
    "                FLIPNUM+=1\n",
    "                tmp = S2.iloc[i,2]\n",
    "                line.extend([atcg(S2.iloc[i,3]),atcg(tmp),0-S2.iloc[i,4],0-S2.iloc[i,5],S2.iloc[i,6], old_id])\n",
    "                FLIPD.append(line)\n",
    "        # at/ta/cg/gc only do ref/alt flip\n",
    "        elif gt(S2.iloc[i,2],S2.iloc[i,3],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0],G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0])==0:\n",
    "            if G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0] == S2.iloc[i,2] and G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0] == S2.iloc[i,3]:\n",
    "                EQUAL+=1\n",
    "                line=S2.iloc[i,:-1].tolist() + [old_id]\n",
    "                FLIPD.append(line)\n",
    "                at_cg_id.append(len(FLIPD) - 1)\n",
    "            elif G2[G2[\"ID\"]==S2.iloc[i,-1]][\"alt\"].iloc[0] == S2.iloc[i,2] and G2[G2[\"ID\"]==S2.iloc[i,-1]][\"ref\"].iloc[0] == S2.iloc[i,3]:\n",
    "                REFALTNUM+=1\n",
    "                line.extend([S2.iloc[i,3],S2.iloc[i,2],0-S2.iloc[i,4],0-S2.iloc[i,5],S2.iloc[i,6], old_id])\n",
    "                FLIPD.append(line)\n",
    "                at_cg_id.append(len(FLIPD) - 1)\n",
    "    if ${strictly_match} and (FLIPNUM > 0 or REFALTNUM > 0):\n",
    "        raise ValueError(f\"Strict panel match failed for locus {locus}.\")\n",
    "    #\n",
    "    print(\"equal:%s\\tflipped by strand:%d\\tflipped by reference and alternative:%d\\n\" % (EQUAL,FLIPNUM,REFALTNUM))\n",
    "    if FLIPNUM > 0:\n",
    "        # flips involved, we need to remove at/ta/cg/gc\n",
    "        FLIPD = [i for j, i in enumerate(FLIPD) if j not in at_cg_id]\n",
    "    S3 = pd.DataFrame(FLIPD, columns=[\"chr\",\"bp\",\"ref\",\"alt\",\"z\", \"beta\", \"se\", \"original_ID\"])\n",
    "    exit_if_empty(S3)\n",
    "    S3[\"ID\"] = S3[\"chr\"] +\":\"+S3[\"bp\"].map(str) + \":\" + S3[\"ref\"] + \":\" + S3[\"alt\"]\n",
    "    G2[\"ID\"] = G2[['ID', 'ref', 'alt']].apply(lambda x: ':'.join(x), axis=1)\n",
    "    # 𝐺3\n",
    "    G3 = G2[G2[\"ID\"].isin(S3[\"ID\"])]\n",
    "    assert G3.shape[0] == S3.shape[0]\n",
    "    # S3 OUT\n",
    "    if \"z\" in S3.columns and \"beta\" in S3.columns and \"se\" in S3.columns:\n",
    "        S3 = S3.drop(columns = [\"z\"])\n",
    "    # recover original ID\n",
    "    print(S3)\n",
    "    S3[\"ID\"] = S3[\"original_ID\"]\n",
    "    S3 = S3.sort_values(by = [\"chr\", \"bp\"]).drop(columns = [\"chr\", \"bp\", \"ref\", \"alt\", \"original_ID\"])\n",
    "    columns = S3.columns.tolist()\n",
    "    columns.insert(0, columns.pop(columns.index('ID')))\n",
    "    S3[columns].to_csv(\"${_output['summary_stats']}\",sep=\"\\t\",index=False)\n",
    "    print(\"SAMPLE: %s\\tLENGTH:%d\\n\" % (\"S3\",len(S3)))\n",
    "    # 𝑅=row_corr(𝐺3) OUT \n",
    "    np.savetxt(\"${_output['ld_matrix']}\", np.corrcoef(G3.drop(columns=['ID', \"ref\",\"alt\"]).values), fmt = '%.5f')\n",
    "#_input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Obtain annotation $A_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_3 (get annotations)]\n",
    "parameter: anno = path()\n",
    "stop_if(not anno.is_file(), msg = 'Quit because annotation file is not found')\n",
    "input: [x for x in output_from(-1) if os.stat(x).st_size > 0], group_by = 2, concurrent = True\n",
    "output: f\"{_input[0]:nn}.{anno:bn}.txt\"\n",
    "python3: expand=\"${ }\", workdir = cwd\n",
    "    import pandas as pd\n",
    "    A1 = pd.read_table(\"${anno}\", compression='gzip', sep=\"\\s+\", header=None)\n",
    "    A1.columns = [\"ID\",\"VALUE\"]\n",
    "    S3 = pd.read_table(\"${_input[0]}\",sep=\"\\t\")\n",
    "    A2 = A1[A1[\"ID\"].isin(S3.iloc[:,0])][[\"ID\",\"VALUE\"]]\n",
    "    A2.to_csv(\"${_output}\",sep=\"\\t\",index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Results of LD chunk 655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Flip summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview /data/chr12_4/Summary_statistics/chunk_4.flip_summary -n --limit 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The number of SNPs in \n",
    "\n",
    "- S1: 8286510\n",
    "- G1: 35634\n",
    "- S2: 112\n",
    "- G2: 112\n",
    "- S3: 67\n",
    "\n",
    "The number of identical SNPs in S2 and G2 is 10; strand flip 50 SNPs; switch ref/alt 7 SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Summary statistics matrix S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview Summary_statistics/chunk_1696.matched_ss.txt -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "### Annotation/prior matrix A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview Summary_statistics/chunk_1696.annotation.txt -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### 𝑅: LD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(read.table('Summary_statistics/chunk_1696.LD.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.17.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
